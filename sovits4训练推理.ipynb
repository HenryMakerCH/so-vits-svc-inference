{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HenryMakerCH/so-vits-svc-notebooks/blob/main/sovits4%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_RcDbVPhivj"
      },
      "source": [
        "## **注意**\n",
        "## **第一次使用该笔记本时，确保你的谷歌硬盘内没有 `sovits4data` 文件夹**\n",
        "## **否则将导致文件夹冲突**\n",
        "## **文件夹将被用来存储必要文件** \n",
        "## **你可以修改 `sovits_data_dir` 变量来更改文件夹存储位置**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHaw6hGEa_Nk"
      },
      "source": [
        "# **配置环境**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gQcIZ8RsOkn",
        "outputId": "28bd134a-ebc0-4de5-c40b-bb87c3e34e58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Mar 14 15:07:13 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   74C    P0    33W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "#@title 查看GPU信息\n",
        "\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YUGpYrXhMck",
        "outputId": "36080443-4d6c-4d3b-afb1-15ebec07f071"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'so-vits-svc'...\n",
            "remote: Enumerating objects: 452, done.\u001b[K\n",
            "remote: Counting objects: 100% (52/52), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 452 (delta 23), reused 48 (delta 20), pack-reused 400\u001b[K\n",
            "Receiving objects: 100% (452/452), 8.10 MiB | 21.06 MiB/s, done.\n",
            "Resolving deltas: 100% (196/196), done.\n",
            "/content/so-vits-svc\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.9/dist-packages (22.0.4)\n",
            "Collecting pip\n",
            "  Downloading pip-23.0.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (63.4.3)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-67.6.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (1.22.4)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.24.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba in /usr/local/lib/python3.9/dist-packages (0.56.4)\n",
            "  Downloading numpy-1.23.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba) (0.39.1)\n",
            "Installing collected packages: setuptools, pip, numpy\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 63.4.3\n",
            "    Uninstalling setuptools-63.4.3:\n",
            "      Successfully uninstalled setuptools-63.4.3\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 22.0.4\n",
            "    Uninstalling pip-22.0.4:\n",
            "      Successfully uninstalled pip-22.0.4\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
            "cvxpy 1.2.3 requires setuptools<=64.0.2, but you have setuptools 67.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5 pip-23.0.1 setuptools-67.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyworld\n",
            "  Downloading pyworld-0.3.2.tar.gz (214 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.4/214.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting praat-parselmouth\n",
            "  Downloading praat_parselmouth-0.4.3-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (10.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fairseq\n",
            "  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.9/dist-packages (from pyworld) (0.29.33)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from pyworld) (1.23.5)\n",
            "Collecting sacrebleu>=1.4.12\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.9/dist-packages (from fairseq) (1.15.1)\n",
            "Collecting omegaconf<2.1\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Collecting bitarray\n",
            "  Downloading bitarray-2.7.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.6/269.6 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from fairseq) (2022.6.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from fairseq) (1.13.1+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from fairseq) (4.65.0)\n",
            "Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from fairseq) (0.13.1+cu116)\n",
            "Collecting hydra-core<1.1,>=1.0.7\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from omegaconf<2.1->fairseq) (4.5.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.9/dist-packages (from omegaconf<2.1->fairseq) (6.0)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.9/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.8.10)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from sacrebleu>=1.4.12->fairseq) (4.9.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi->fairseq) (2.21)\n",
            "Building wheels for collected packages: pyworld, fairseq, antlr4-python3-runtime\n",
            "  Building wheel for pyworld (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyworld: filename=pyworld-0.3.2-cp39-cp39-linux_x86_64.whl size=895637 sha256=8fab9a9294f3ae3cbb5a90fe709f9a6471d2231092fdc90e983d28d007c47009\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/91/01/58aa68f1f055ce534049e668292b710500100da0262079b8f5\n",
            "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.12.2-cp39-cp39-linux_x86_64.whl size=11179742 sha256=044333c492f1b338a75596a1350d74d2eea310c2f1c26fba529f77c42dd11d59\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/35/87/2baf2e4ad37c83fd698c486b3d39f0e7022226fa52ab469c31\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141231 sha256=171524151ca13ad8893b467e5b067400053ba48dcfcb01307c3849c407ae0050\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/3c/ae/14db087e6018de74810afe32eb6ac890ef9c68ba19b00db97a\n",
            "Successfully built pyworld fairseq antlr4-python3-runtime\n",
            "Installing collected packages: bitarray, antlr4-python3-runtime, pyworld, praat-parselmouth, portalocker, omegaconf, colorama, sacrebleu, hydra-core, fairseq\n",
            "Successfully installed antlr4-python3-runtime-4.8 bitarray-2.7.3 colorama-0.4.6 fairseq-0.12.2 hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.7.0 praat-parselmouth-0.4.3 pyworld-0.3.2 sacrebleu-2.3.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#@title 克隆sovits4库并安装需求环境\n",
        "\n",
        "\n",
        "!git clone https://github.com/svc-develop-team/so-vits-svc -b 4.0\n",
        "%cd /content/so-vits-svc\n",
        "!pip install --upgrade pip setuptools numpy numba\n",
        "!pip install pyworld praat-parselmouth fairseq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmUkpUmfn_Hs",
        "outputId": "0569f4f8-b11d-40e8-a969-6da1859585be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title 装载谷歌硬盘 选择文件夹位置\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "#@markdown 存储 **重要文件** 的文件夹，别忘了后面的斜杠 `/`\n",
        "sovits_data_dir = \"/content/drive/MyDrive/sovits4data/\"  #@param {type:\"string\"}\n",
        "RAW_DIR = sovits_data_dir + \"raw/\"\n",
        "RESULTS_DIR = sovits_data_dir + \"results/\"\n",
        "FILELISTS_DIR = sovits_data_dir + \"filelists/\"\n",
        "CONFIGS_DIR = sovits_data_dir + \"configs/\"\n",
        "LOGS_DIR = sovits_data_dir + \"logs/44k/\"\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown　### **强烈建议全部勾选**\n",
        "\n",
        "#@markdown 同步 **输入音频** 和 **输出音频**\n",
        "sync_raw_and_results = True  #@param {type:\"boolean\"}\n",
        "if sync_raw_and_results:\n",
        "  !mkdir -p {RAW_DIR}\n",
        "  !mkdir -p {RESULTS_DIR}\n",
        "  !rm -rf /content/so-vits-svc/raw\n",
        "  !rm -rf /content/so-vits-svc/results\n",
        "  !ln -s {RAW_DIR} /content/so-vits-svc/raw\n",
        "  !ln -s {RESULTS_DIR} /content/so-vits-svc/results\n",
        "\n",
        "#@markdown 同步 **配置文件** 和 **模型**\n",
        "sync_configs_and_logs = True  #@param {type:\"boolean\"}\n",
        "if sync_configs_and_logs:\n",
        "  !mkdir -p {FILELISTS_DIR}\n",
        "  !mkdir -p {CONFIGS_DIR}\n",
        "  !mkdir -p {LOGS_DIR}\n",
        "  !rm -rf /content/so-vits-svc/filelists\n",
        "  !rm -rf /content/so-vits-svc/configs\n",
        "  !rm -rf /content/so-vits-svc/logs/44k\n",
        "  !ln -s {FILELISTS_DIR} /content/so-vits-svc/filelists\n",
        "  !ln -s {CONFIGS_DIR} /content/so-vits-svc/configs\n",
        "  !ln -s {LOGS_DIR} /content/so-vits-svc/logs/44k\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCqf3W0d6ify",
        "outputId": "60df1e25-3252-4cab-d4b8-4aab43cf623c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/drive/MyDrive/sovits4data/hubert/checkpoint_best_legacy_500.pt' -> '/content/so-vits-svc/hubert/checkpoint_best_legacy_500.pt'\n"
          ]
        }
      ],
      "source": [
        "#@title 获取必要模型\n",
        "\n",
        "\n",
        "#@markdown ## [auspicious3000/contentvec](https://github.com/auspicious3000/contentvec)：\n",
        "\n",
        "#@markdown #### 下载地址 [https://ibm.box.com/s/z1wgl1stco8ffooyatzdwsqn2psd9lrr](https://ibm.box.com/s/z1wgl1stco8ffooyatzdwsqn2psd9lrr)\n",
        "#@markdown #### 手动上传到谷歌硬盘 /sovits4data/hubert/\n",
        "#@markdown #### 没有下载直链\n",
        "#@markdown **你下载的contentvec模型** 的存储文件夹, 别忘了后面的斜杠 `/`\n",
        "sovits_data_dir = \"/content/drive/MyDrive/sovits4data/hubert/\"  #@param {type:\"string\"}\n",
        "#@markdown **你下载的contentvec模型** 的文件名\n",
        "contentvec_filename = \"checkpoint_best_legacy_500.pt\"  #@param {type:\"string\"}\n",
        "CONTENTVEC_PATH = sovits_data_dir + contentvec_filename\n",
        "\n",
        "!cp -v {CONTENTVEC_PATH} /content/so-vits-svc/hubert/checkpoint_best_legacy_500.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_PMPCN6wvgZ"
      },
      "outputs": [],
      "source": [
        "#@title 获取预训练模型（强烈建议）\n",
        "\n",
        "\n",
        "#@markdown - 预训练模型: `G_0.pth` `D_0.pth`\n",
        "#@markdown   - 上传到谷歌硬盘 /sovits4data/logs/44k/\n",
        "\n",
        "#@markdown 从svc-develop-team(不确定)或者其他什么地方搞\n",
        "\n",
        "#@markdown Although the pretrained model generally does not cause any copyright problems, please pay attention to it. For example, ask the author in advance, or the author has indicated the feasible use in the description clearly.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1qadJBFehMo"
      },
      "source": [
        "# **数据集处理**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBlju6Q3lSM6"
      },
      "source": [
        "把打包后的数据传到 dataset_raw/\n",
        "\n",
        "音频文件名不做要求\n",
        "\n",
        "确保zip文件结构如下\n",
        "\n",
        "\n",
        "```\n",
        "yourzipfilename.zip\n",
        "├───speaker0\n",
        "│   ├───***.wav\n",
        "│   ├───...\n",
        "│   └───***.wav\n",
        "└───speaker1\n",
        "    ├───***.wav\n",
        "    ├───...\n",
        "    └───***.wav\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U05CXlAipvJR",
        "outputId": "21631119-f33f-48d3-a451-c66f8b512816"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/sovits4data/henrymaker.zip\n",
            "   creating: /content/so-vits-svc/dataset_raw/henrymaker/\n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_en_1.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_en_10.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_en_2.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_en_3.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_en_4.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_en_5.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_en_6.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_en_7.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_en_8.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_en_9.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_jp_1.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_jp_10.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_jp_2.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_jp_3.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_jp_4.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_jp_5.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_jp_501.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_jp_502.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_jp_503.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_jp_504.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_jp_505.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_jp_506.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_jp_6.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_jp_7.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_jp_8.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_jp_9.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_zh_1.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_zh_10.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_zh_2.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_zh_3.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_zh_4.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_zh_5.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_zh_6.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_zh_7.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_zh_8.wav  \n",
            "  inflating: /content/so-vits-svc/dataset_raw/henrymaker/vocal_zh_9.wav  \n"
          ]
        }
      ],
      "source": [
        "#@title 从谷歌硬盘读取数据集\n",
        "\n",
        "\n",
        "#@markdown  **zip 文件**存储路径, 别忘了后面的斜杠 `/`\n",
        "sovits_data_dir = \"/content/drive/MyDrive/sovits4data/\"  #@param {type:\"string\"}\n",
        "#@markdown **你的 zip 文件名**，请勿命名为 \"dataset.zip\"\n",
        "zip_filename = \"henrymaker.zip\"  #@param {type:\"string\"}\n",
        "ZIP_PATH = sovits_data_dir + zip_filename\n",
        "\n",
        "!unzip -od /content/so-vits-svc/dataset_raw {ZIP_PATH}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ThKTzYs5CfL",
        "outputId": "90ca3dd9-c3a7-4eb3-b85d-7b884d2661d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./dataset_raw/henrymaker\n",
            "36it [00:18,  1.93it/s]\n"
          ]
        }
      ],
      "source": [
        "#@title 重采样到44100Hz\n",
        "\n",
        "!python resample.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svITReeL5N8K",
        "outputId": "5bb8224a-a831-4df1-d226-f4383fdd5fb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r  0% 0/1 [00:00<?, ?it/s]\r100% 1/1 [00:00<00:00, 475.65it/s]\n",
            "Writing ./filelists/train.txt\n",
            "\r  0% 0/32 [00:00<?, ?it/s]\r100% 32/32 [00:00<00:00, 453438.27it/s]\n",
            "Writing ./filelists/val.txt\n",
            "\r  0% 0/2 [00:00<?, ?it/s]\r100% 2/2 [00:00<00:00, 60787.01it/s]\n",
            "Writing ./filelists/test.txt\n",
            "\r  0% 0/2 [00:00<?, ?it/s]\r100% 2/2 [00:00<00:00, 64035.18it/s]\n",
            "Writing configs/config.json\n"
          ]
        }
      ],
      "source": [
        "#@title 分割文件列表，生成配置文件\n",
        "\n",
        "!python preprocess_flist_config.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHUXMi836DMe",
        "outputId": "9e4bc5a6-cfde-433d-89f7-ce7c1a386262"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[36]\n",
            "Loading hubert for content...\n",
            "load model(s) from hubert/checkpoint_best_legacy_500.pt\n",
            "INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX\n",
            "INFO:fairseq.tasks.hubert_pretraining:current directory is /content/so-vits-svc\n",
            "INFO:fairseq.tasks.hubert_pretraining:HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'metadata', 'fine_tuning': False, 'labels': ['km'], 'label_dir': 'label', 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}\n",
            "INFO:fairseq.models.hubert.hubert:HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.1, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}\n",
            "Loaded hubert.\n",
            "100% 36/36 [00:42<00:00,  1.19s/it]\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#@title 生成 hubert 和 f0\n",
        "\n",
        "!python preprocess_hubert_f0.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wo4OTmTAUXgj",
        "outputId": "33de1aba-ff02-41db-fe61-72da9d3d20c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/so-vits-svc/dataset/ (stored 0%)\n",
            "  adding: content/so-vits-svc/dataset/44k/ (stored 0%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/ (stored 0%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_8.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_506.wav.f0.npy (deflated 56%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_504.wav.f0.npy (deflated 50%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_en_8.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_8.wav.f0.npy (deflated 58%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_1.wav.f0.npy (deflated 36%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_9.wav.f0.npy (deflated 40%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_8.wav.f0.npy (deflated 44%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_1.wav (deflated 9%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_10.wav (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_1.wav (deflated 10%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_en_2.wav.f0.npy (deflated 41%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_3.wav (deflated 9%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_5.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_3.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_9.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_en_7.wav (deflated 9%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_4.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_10.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_504.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_9.wav.f0.npy (deflated 53%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_7.wav.f0.npy (deflated 51%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_5.wav.f0.npy (deflated 45%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_3.wav.f0.npy (deflated 51%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_2.wav.f0.npy (deflated 38%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_6.wav (deflated 6%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_6.wav (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_10.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_6.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_1.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_en_2.wav (deflated 5%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_506.wav (deflated 10%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_en_10.wav (deflated 7%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_4.wav (deflated 7%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_3.wav (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_en_8.wav (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_8.wav (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_en_10.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_en_6.wav.f0.npy (deflated 40%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_2.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_en_9.wav (deflated 6%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_6.wav.f0.npy (deflated 46%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_9.wav (deflated 12%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_8.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_505.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_en_3.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_2.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_502.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_501.wav.f0.npy (deflated 61%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_1.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_10.wav.f0.npy (deflated 48%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_en_7.wav.f0.npy (deflated 46%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_503.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_en_3.wav.f0.npy (deflated 44%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_5.wav.f0.npy (deflated 64%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_en_4.wav.f0.npy (deflated 47%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_en_5.wav (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_en_6.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_9.wav (deflated 7%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_en_7.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_8.wav (deflated 7%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_en_5.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_en_10.wav.f0.npy (deflated 51%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_en_4.wav (deflated 7%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_501.wav (deflated 9%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_3.wav.f0.npy (deflated 36%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_en_3.wav (deflated 9%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_en_2.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_5.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_en_1.wav (deflated 7%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_502.wav (deflated 9%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_10.wav.f0.npy (deflated 49%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_9.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_502.wav.f0.npy (deflated 53%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_1.wav.f0.npy (deflated 50%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_505.wav.f0.npy (deflated 65%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_en_6.wav (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_506.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_5.wav (deflated 7%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_505.wav (deflated 13%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_en_9.wav.f0.npy (deflated 39%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_2.wav (deflated 9%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_4.wav (deflated 9%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_7.wav (deflated 5%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_3.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_en_9.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_4.wav.f0.npy (deflated 58%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_5.wav (deflated 7%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_4.wav.f0.npy (deflated 34%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_7.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_4.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_en_1.wav.f0.npy (deflated 46%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_503.wav (deflated 10%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_7.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_2.wav.f0.npy (deflated 53%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_en_4.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_en_8.wav.f0.npy (deflated 54%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_504.wav (deflated 10%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_en_1.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_503.wav.f0.npy (deflated 56%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_6.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_7.wav (deflated 10%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_501.wav.soft.pt (deflated 8%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_2.wav (deflated 7%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_7.wav.f0.npy (deflated 49%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_6.wav.f0.npy (deflated 51%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_en_5.wav.f0.npy (deflated 39%)\n",
            "  adding: content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_10.wav (deflated 7%)\n",
            "'dataset.zip' -> '/content/drive/MyDrive/sovits4data/henrymaker/dataset.zip'\n"
          ]
        }
      ],
      "source": [
        "#@title 存储已处理数据集\n",
        "\n",
        "#@markdown 把已处理过的数据集保存至谷歌硬盘以便下次训练\n",
        "\n",
        "#@markdown **存储路径**, 别忘了后面的斜杠 `/`\n",
        "sovits_data_dir = \"/content/drive/MyDrive/sovits4data/henrymaker/\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown 你的谷歌硬盘内会有一个 `dataset.zip` 文件，内含 `dataset/` ，即为已处理数据集\n",
        "\n",
        "!mkdir -p {sovits_data_dir}\n",
        "!zip -r dataset.zip /content/so-vits-svc/dataset\n",
        "!cp -vr dataset.zip \"{sovits_data_dir}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENoH-pShel7w"
      },
      "source": [
        "# **训练**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2G6v_6zblWK",
        "outputId": "901a6c75-23a7-4838-b773-698ae96e5254"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: '/content/drive/MyDrive/sovits4data/configs/' and '/content/so-vits-svc/configs' are the same file\n",
            "cp: '/content/drive/MyDrive/sovits4data/filelists/' and '/content/so-vits-svc/filelists' are the same file\n",
            "Archive:  /content/drive/MyDrive/sovits4data/dataset.zip\n",
            "   creating: /content/so-vits-svc/dataset/\n",
            "   creating: /content/so-vits-svc/dataset/44k/\n",
            "   creating: /content/so-vits-svc/dataset/44k/henrymaker/\n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_8.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_506.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_504.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_en_8.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_8.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_1.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_9.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_8.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_1.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_10.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_1.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_en_2.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_3.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_5.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_3.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_9.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_en_7.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_4.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_10.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_504.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_9.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_7.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_5.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_3.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_2.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_6.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_6.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_10.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_6.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_1.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_en_2.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_506.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_en_10.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_4.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_3.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_en_8.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_8.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_en_10.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_en_6.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_2.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_en_9.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_6.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_9.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_8.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_505.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_en_3.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_2.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_502.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_501.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_1.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_10.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_en_7.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_503.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_en_3.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_5.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_en_4.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_en_5.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_en_6.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_9.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_en_7.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_8.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_en_5.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_en_10.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_en_4.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_501.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_3.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_en_3.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_en_2.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_5.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_en_1.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_502.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_10.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_9.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_502.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_1.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_505.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_en_6.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_506.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_5.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_505.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_en_9.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_2.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_4.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_7.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_3.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_en_9.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_4.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_5.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_4.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_7.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_4.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_en_1.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_503.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_7.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_2.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_en_4.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_en_8.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_504.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_en_1.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_503.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_6.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_7.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_501.wav.soft.pt  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_jp_2.wav  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_7.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_6.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_en_5.wav.f0.npy  \n",
            "  inflating: /content/so-vits-svc/dataset/44k/henrymaker/vocal_zh_10.wav  \n"
          ]
        }
      ],
      "source": [
        "#@title 从谷歌硬盘解压已有预处理数据集\n",
        "\n",
        "#@markdown **你的已预处理数据集**的存储路径，别忘了后面的斜杠 `/`\n",
        "sovits_data_dir = \"/content/drive/MyDrive/sovits4data/\" #@param {type:\"string\"}\n",
        "CONFIG = sovits_data_dir + \"configs/\"\n",
        "FILELISTS = sovits_data_dir + \"filelists/\"\n",
        "DATASET = sovits_data_dir + \"dataset.zip\"\n",
        "\n",
        "!cp -vr {CONFIG} /content/so-vits-svc/\n",
        "!cp -vr {FILELISTS} /content/so-vits-svc/\n",
        "!unzip {DATASET} -d /"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hEFFTCfZf57",
        "outputId": "ac8245ce-cecc-4941-842b-18382dddb79f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:44k:{'train': {'log_interval': 100, 'eval_interval': 1000, 'seed': 1234, 'epochs': 10000, 'learning_rate': 0.0001, 'betas': [0.8, 0.99], 'eps': 1e-09, 'batch_size': 6, 'fp16_run': False, 'lr_decay': 0.999875, 'segment_size': 10240, 'init_lr_ratio': 1, 'warmup_epochs': 0, 'c_mel': 45, 'c_kl': 1.0, 'use_sr': True, 'max_speclen': 512, 'port': '8001', 'keep_ckpts': 3}, 'data': {'training_files': 'filelists/train.txt', 'validation_files': 'filelists/val.txt', 'max_wav_value': 32768.0, 'sampling_rate': 44100, 'filter_length': 2048, 'hop_length': 512, 'win_length': 2048, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 22050}, 'model': {'inter_channels': 192, 'hidden_channels': 192, 'filter_channels': 768, 'n_heads': 2, 'n_layers': 6, 'kernel_size': 3, 'p_dropout': 0.1, 'resblock': '1', 'resblock_kernel_sizes': [3, 7, 11], 'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'upsample_rates': [8, 8, 2, 2, 2], 'upsample_initial_channel': 512, 'upsample_kernel_sizes': [16, 16, 4, 4, 4], 'n_layers_q': 3, 'use_spectral_norm': False, 'gin_channels': 256, 'ssl_dim': 256, 'n_speakers': 200}, 'spk': {'henrymaker': 0}, 'model_dir': './logs/44k'}\n",
            "WARNING:44k:git hash values are different. b3430e73(saved) != 55dd086f(current)\n",
            "2023-03-15 15:47:08.746180: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "DEBUG:tensorflow:Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
            "2023-03-15 15:47:09.752709: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-15 15:47:09.752832: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-15 15:47:09.752853: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
            "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
            "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
            "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
            "DEBUG:jaxlib.mlir._mlir_libs:Initializing MLIR with module: _site_initialize_0\n",
            "DEBUG:jaxlib.mlir._mlir_libs:Registering dialects from initializer <module 'jaxlib.mlir._mlir_libs._site_initialize_0' from '/usr/local/lib/python3.9/dist-packages/jaxlib/mlir/_mlir_libs/_site_initialize_0.so'>\n",
            "DEBUG:jax._src.path:etils.epath found. Using etils.epath for file I/O.\n",
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 0\n",
            "INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n",
            "./logs/44k/G_6000.pth\n",
            "load \n",
            "INFO:44k:Loaded checkpoint './logs/44k/G_6000.pth' (iteration 1001)\n",
            "./logs/44k/D_6000.pth\n",
            "load \n",
            "INFO:44k:Loaded checkpoint './logs/44k/D_6000.pth' (iteration 1001)\n",
            "INFO:torch.nn.parallel.distributed:Reducer buckets have been rebuilt in this iteration.\n",
            "/usr/local/lib/python3.9/dist-packages/torch/autograd/__init__.py:197: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\n",
            "grad.sizes() = [32, 1, 4], strides() = [4, 1, 1]\n",
            "bucket_view.sizes() = [32, 1, 4], strides() = [4, 4, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:325.)\n",
            "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "INFO:44k:Train Epoch: 1001 [0%]\n",
            "INFO:44k:Losses: [2.649219274520874, 1.820237159729004, 2.492065191268921, 16.134620666503906, 0.4524992108345032], step: 6000, lr: 7.467549064360665e-05\n",
            "INFO:44k:Saving model and optimizer state at iteration 1001 to ./logs/44k/G_6000.pth\n",
            "INFO:44k:Saving model and optimizer state at iteration 1001 to ./logs/44k/D_6000.pth\n",
            "INFO:torch.nn.parallel.distributed:Reducer buckets have been rebuilt in this iteration.\n",
            "INFO:44k:====> Epoch: 1001, cost 66.24 s\n",
            "INFO:44k:====> Epoch: 1002, cost 14.21 s\n",
            "INFO:44k:====> Epoch: 1003, cost 12.38 s\n",
            "INFO:44k:====> Epoch: 1004, cost 11.64 s\n",
            "INFO:44k:====> Epoch: 1005, cost 12.81 s\n",
            "INFO:44k:====> Epoch: 1006, cost 13.39 s\n",
            "INFO:44k:====> Epoch: 1007, cost 11.33 s\n",
            "INFO:44k:====> Epoch: 1008, cost 11.63 s\n",
            "INFO:44k:====> Epoch: 1009, cost 12.32 s\n",
            "INFO:44k:====> Epoch: 1010, cost 13.81 s\n",
            "INFO:44k:====> Epoch: 1011, cost 12.25 s\n",
            "INFO:44k:====> Epoch: 1012, cost 12.31 s\n",
            "INFO:44k:====> Epoch: 1013, cost 12.08 s\n",
            "INFO:44k:====> Epoch: 1014, cost 13.69 s\n",
            "INFO:44k:====> Epoch: 1015, cost 14.18 s\n",
            "INFO:44k:====> Epoch: 1016, cost 12.53 s\n",
            "INFO:44k:Train Epoch: 1017 [67%]\n",
            "INFO:44k:Losses: [2.8559999465942383, 1.6692543029785156, 2.0472500324249268, 16.292869567871094, 0.5156792402267456], step: 6100, lr: 7.452627959722119e-05\n",
            "INFO:44k:====> Epoch: 1017, cost 12.90 s\n",
            "INFO:44k:====> Epoch: 1018, cost 11.87 s\n",
            "INFO:44k:====> Epoch: 1019, cost 12.98 s\n",
            "INFO:44k:====> Epoch: 1020, cost 14.47 s\n",
            "INFO:44k:====> Epoch: 1021, cost 13.21 s\n",
            "INFO:44k:====> Epoch: 1022, cost 11.83 s\n",
            "INFO:44k:====> Epoch: 1023, cost 11.77 s\n",
            "INFO:44k:====> Epoch: 1024, cost 13.05 s\n",
            "INFO:44k:====> Epoch: 1025, cost 14.16 s\n",
            "INFO:44k:====> Epoch: 1026, cost 12.51 s\n",
            "INFO:44k:====> Epoch: 1027, cost 11.97 s\n",
            "INFO:44k:====> Epoch: 1028, cost 12.35 s\n",
            "INFO:44k:====> Epoch: 1029, cost 13.42 s\n",
            "INFO:44k:====> Epoch: 1030, cost 13.98 s\n",
            "INFO:44k:====> Epoch: 1031, cost 12.05 s\n",
            "INFO:44k:====> Epoch: 1032, cost 11.84 s\n",
            "INFO:44k:====> Epoch: 1033, cost 12.10 s\n",
            "INFO:44k:Train Epoch: 1034 [33%]\n",
            "INFO:44k:Losses: [2.7476966381073, 2.046236515045166, 2.9076571464538574, 16.310550689697266, 0.5248098373413086], step: 6200, lr: 7.436806952248426e-05\n",
            "INFO:44k:====> Epoch: 1034, cost 14.49 s\n",
            "INFO:44k:====> Epoch: 1035, cost 14.31 s\n",
            "INFO:44k:====> Epoch: 1036, cost 13.01 s\n",
            "INFO:44k:====> Epoch: 1037, cost 11.97 s\n",
            "INFO:44k:====> Epoch: 1038, cost 12.20 s\n",
            "INFO:44k:====> Epoch: 1039, cost 12.33 s\n",
            "INFO:44k:====> Epoch: 1040, cost 14.11 s\n",
            "INFO:44k:====> Epoch: 1041, cost 13.09 s\n",
            "INFO:44k:====> Epoch: 1042, cost 11.94 s\n",
            "INFO:44k:====> Epoch: 1043, cost 12.07 s\n",
            "INFO:44k:====> Epoch: 1044, cost 12.99 s\n",
            "INFO:44k:====> Epoch: 1045, cost 13.86 s\n",
            "INFO:44k:====> Epoch: 1046, cost 13.44 s\n",
            "INFO:44k:====> Epoch: 1047, cost 11.61 s\n",
            "INFO:44k:====> Epoch: 1048, cost 11.61 s\n",
            "INFO:44k:====> Epoch: 1049, cost 12.84 s\n",
            "INFO:44k:====> Epoch: 1050, cost 13.74 s\n",
            "INFO:44k:Train Epoch: 1051 [0%]\n",
            "INFO:44k:Losses: [2.4664669036865234, 1.6951771974563599, 3.2634482383728027, 15.11942195892334, 0.4974312484264374], step: 6300, lr: 7.421019530816979e-05\n",
            "INFO:44k:====> Epoch: 1051, cost 13.17 s\n",
            "INFO:44k:====> Epoch: 1052, cost 11.95 s\n",
            "INFO:44k:====> Epoch: 1053, cost 11.62 s\n",
            "INFO:44k:====> Epoch: 1054, cost 13.05 s\n",
            "INFO:44k:====> Epoch: 1055, cost 13.60 s\n",
            "INFO:44k:====> Epoch: 1056, cost 11.81 s\n",
            "INFO:44k:====> Epoch: 1057, cost 12.04 s\n",
            "INFO:44k:====> Epoch: 1058, cost 11.86 s\n",
            "INFO:44k:====> Epoch: 1059, cost 13.24 s\n",
            "INFO:44k:====> Epoch: 1060, cost 13.27 s\n",
            "INFO:44k:====> Epoch: 1061, cost 11.37 s\n",
            "INFO:44k:====> Epoch: 1062, cost 11.77 s\n",
            "INFO:44k:====> Epoch: 1063, cost 12.39 s\n",
            "INFO:44k:====> Epoch: 1064, cost 13.41 s\n",
            "INFO:44k:====> Epoch: 1065, cost 12.20 s\n",
            "INFO:44k:====> Epoch: 1066, cost 11.79 s\n",
            "INFO:44k:Train Epoch: 1067 [67%]\n",
            "INFO:44k:Losses: [2.8427529335021973, 1.8986226320266724, 1.7021849155426025, 12.847583770751953, 0.10640408843755722], step: 6400, lr: 7.406191398053517e-05\n",
            "INFO:44k:====> Epoch: 1067, cost 12.74 s\n",
            "INFO:44k:====> Epoch: 1068, cost 12.44 s\n",
            "INFO:44k:====> Epoch: 1069, cost 13.81 s\n",
            "INFO:44k:====> Epoch: 1070, cost 12.53 s\n",
            "INFO:44k:====> Epoch: 1071, cost 12.29 s\n",
            "INFO:44k:====> Epoch: 1072, cost 12.32 s\n",
            "INFO:44k:====> Epoch: 1073, cost 12.80 s\n",
            "INFO:44k:====> Epoch: 1074, cost 14.19 s\n",
            "INFO:44k:====> Epoch: 1075, cost 12.86 s\n",
            "INFO:44k:====> Epoch: 1076, cost 11.82 s\n",
            "INFO:44k:====> Epoch: 1077, cost 11.61 s\n",
            "INFO:44k:====> Epoch: 1078, cost 12.66 s\n",
            "INFO:44k:====> Epoch: 1079, cost 13.76 s\n",
            "INFO:44k:====> Epoch: 1080, cost 12.07 s\n",
            "INFO:44k:====> Epoch: 1081, cost 12.34 s\n",
            "INFO:44k:====> Epoch: 1082, cost 12.42 s\n",
            "INFO:44k:====> Epoch: 1083, cost 13.29 s\n",
            "INFO:44k:Train Epoch: 1084 [33%]\n",
            "INFO:44k:Losses: [2.7854201793670654, 1.8285088539123535, 3.077756881713867, 16.97039222717285, 0.4729904234409332], step: 6500, lr: 7.390468969657324e-05\n",
            "INFO:44k:====> Epoch: 1084, cost 14.55 s\n",
            "INFO:44k:====> Epoch: 1085, cost 13.27 s\n",
            "INFO:44k:====> Epoch: 1086, cost 11.95 s\n",
            "INFO:44k:====> Epoch: 1087, cost 11.84 s\n",
            "INFO:44k:====> Epoch: 1088, cost 12.64 s\n",
            "INFO:44k:====> Epoch: 1089, cost 13.88 s\n",
            "INFO:44k:====> Epoch: 1090, cost 12.61 s\n",
            "INFO:44k:====> Epoch: 1091, cost 12.27 s\n",
            "INFO:44k:====> Epoch: 1092, cost 12.12 s\n",
            "INFO:44k:====> Epoch: 1093, cost 13.25 s\n",
            "INFO:44k:====> Epoch: 1094, cost 13.95 s\n",
            "INFO:44k:====> Epoch: 1095, cost 11.73 s\n",
            "INFO:44k:====> Epoch: 1096, cost 12.18 s\n",
            "INFO:44k:====> Epoch: 1097, cost 11.94 s\n",
            "INFO:44k:====> Epoch: 1098, cost 13.85 s\n",
            "INFO:44k:====> Epoch: 1099, cost 12.84 s\n",
            "INFO:44k:====> Epoch: 1100, cost 11.93 s\n",
            "INFO:44k:Train Epoch: 1101 [0%]\n",
            "INFO:44k:Losses: [2.787208080291748, 1.8029310703277588, 1.721549153327942, 13.480664253234863, 0.5032892227172852], step: 6600, lr: 7.374779918032184e-05\n",
            "INFO:44k:====> Epoch: 1101, cost 12.74 s\n",
            "INFO:44k:====> Epoch: 1102, cost 12.15 s\n"
          ]
        }
      ],
      "source": [
        "#@title 开始训练\n",
        "\n",
        "#@markdown 如果你要使用预训练模型，把它们上传到谷歌硬盘的 /sovits4data/logs/44k/\n",
        "\n",
        "#@markdown 是否启用Tensorboard\n",
        "tensorboard_on = False  #@param {type:\"boolean\"}\n",
        "\n",
        "if tensorboard_on:\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir logs/44k\n",
        "\n",
        "!python train.py -c configs/config.json -m 44k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZThaMxmIJgWy"
      },
      "outputs": [],
      "source": [
        "#@title 训练聚类模型（可选）\n",
        "\n",
        "#@markdown 详情见 [README.md#cluster-based-timbre-leakage-control](https://github.com/svc-develop-team/so-vits-svc#cluster-based-timbre-leakage-control)\n",
        "\n",
        "!python cluster/train_cluster.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCnbX-OT897k"
      },
      "source": [
        "# **推理**\n",
        "### 从notebook中上传\n",
        "### **或者**\n",
        "### 手动上传到谷歌硬盘 /sovits4data/raw/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUsmGkgCMD_Q"
      },
      "outputs": [],
      "source": [
        "#@title 上传wav文件，文件名不应含有特殊字符如 `#` `$` `(` `)`\n",
        "\n",
        "%run wav_upload.py --type audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYnKuKTIj3z1"
      },
      "outputs": [],
      "source": [
        "#@title 开始推理及下载\n",
        "\n",
        "#@markdown 参数设置详见 [README.MD#inference](https://github.com/svc-develop-team/so-vits-svc#inference)\n",
        "\n",
        "#@markdown\n",
        "\n",
        "wav_filename = \"LYTD_vocal.wav\"  #@param {type:\"string\"}\n",
        "model_filename = \"G_800.pth\"  #@param {type:\"string\"}\n",
        "model_path = \"/content/so-vits-svc/logs/44k/\" + model_filename\n",
        "speaker = \"henrymaker\"  #@param {type:\"string\"}\n",
        "trans = \"0\"  #@param {type:\"string\"}\n",
        "cluster_infer_ratio = \"0\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown 通常保持默认：\n",
        "config_filename = \"config.json\"  #@param {type:\"string\"}\n",
        "config_path = \"/content/so-vits-svc/configs/\" + config_filename\n",
        "slice_db = \"-40\"  #@param {type:\"string\"}\n",
        "wav_format = \"flac\"  #@param {type:\"string\"}\n",
        "wav_output = \"/content/so-vits-svc/results/\" + wav_filename + \"_\" + trans + \"key\" + \"_\" + speaker + \".\" + wav_format\n",
        "\n",
        "!python inference_main.py -n {wav_filename} -m {model_path} -c {config_path} -s {speaker} -t {trans} -cr {cluster_infer_ratio} -sd {slice_db} -wf {wav_format}\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown 如果你不想直接从这里下载，请取消复选框\n",
        "download_after_inference = True  #@param {type:\"boolean\"}\n",
        "\n",
        "if download_after_inference:\n",
        "  from google.colab import files\n",
        "  files.download(wav_output)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}